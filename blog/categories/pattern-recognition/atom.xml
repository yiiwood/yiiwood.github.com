<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Pattern Recognition | Yiiwood's Blog]]></title>
  <link href="http://yiiwood.github.com/blog/categories/pattern-recognition/atom.xml" rel="self"/>
  <link href="http://yiiwood.github.com/"/>
  <updated>2013-03-07T19:20:22+08:00</updated>
  <id>http://yiiwood.github.com/</id>
  <author>
    <name><![CDATA[Yiiwood]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[用于分类的几种图像表示模型]]></title>
    <link href="http://yiiwood.github.com/blog/2012/11/23/Image-Representation-For-Classification/"/>
    <updated>2012-11-23T20:31:00+08:00</updated>
    <id>http://yiiwood.github.com/blog/2012/11/23/Image-Representation-For-Classification</id>
    <content type="html"><![CDATA[<h2 id="section">图像分类的一般框架</h2>
<p>图像分类是涉及计算机视觉、机器学习、模式识别等领域的一项交叉研究，具有广阔的应用前景。一般框架如下图所示，包括图像特征提取、图像特征编码与表示、图像分类与检索。</p>

<p><img src="../images/Image-Representation-For-Classification/image-classification-framework.png" alt="classification-framework" /></p>

<!-- more -->

<p>通常图像特征分为全局特征和局部特征，全局特征需要在整幅图像中计算，常用的有全局颜色直方图、功率谱、PHOG等；局部特征计算方式和全局特征方法相反，它首先将图像划分成图像块，再对各个小图像块计算其特征表示，常用的局部特征有GIST、SIFT、SURF、MSER 等。在应用中，由于局部特征鲁棒性好、能够应对多种变换等，因此在分类与识别领域扮演着重要角色。</p>

<p>图像表示是指组织图像特征表达整幅图像或图中目标，当用局部特征表示图像时，由于每幅图像会有很多局部特征，这样特征之间的组织关系就变得十分重要，良好的组织关系使得图像表示更具区分性，并且能捕捉图中目标的结构信息，为后续的分类打好基础。当前比较有代表性的方法包括特征袋（BOW）方法和空间金字塔匹配方法。其中空间金字塔匹配方法又包括基本空间金字塔匹配(Spatial Pyramid Matching, SPM)法、稀疏编码空间金字塔匹配(Sparse coding SPM, ScSPM)法和局部性约束线性编码(Locality-constrained Linear Coding, LLC)空间金字塔匹配法。这几类表示模型也是我们接下来要讨论和评估的。</p>

<p>图像分类里用的最多的是SVM，另外也有衡量不同可视特征对于图像分类重要性的多核学习方法（Multiple Kernel Learning，MKL）。源于自然语言处理主题模型(Topic Model)中的LDA（Latent Dirichlet Allocation）和PLSA（Probabilistic Latent Semantic Analysis）模型也可用于图像分类，该类方法主要是通过图像特征的集合得到隐含的图像主题。与朴素贝叶斯方法相比，LDA和PLSA更适合解决大规模数据的问题。</p>

<h2 id="section-1">几种图像表示模型</h2>

<hr />
<p><img src="../images/Image-Representation-For-Classification/BOW.png" alt="classification-framework" /></p>

<ul>
  <li><strong><em>BOW:</em></strong><br />
1.局部特征提取与描述；<br />
2.构建大规模、区分力强的视词字典；<br />
3.准确而快速地进行特征向量量化；<br />
4.计算每幅图像的视词直方图；<br />
5.使用TF-IDF策略对视词直方图进行加权。  </li>
</ul>

<hr />

<p><img src="../images/Image-Representation-For-Classification/SPM.png" alt="classification-framework" /></p>

<ul>
  <li><strong><em>SPM:</em></strong><br />
1.局部特征提取与描述；<br />
2.构建大规模、区分力强的视词字典； <br />
3.准确而快速地进行特征向量量化； <br />
4.计算每个区域的视词直方图组成空间金字塔。</li>
</ul>

<p><img src="../images/Image-Representation-For-Classification/3-SPM.png" alt="classification-framework" /><br />
3层空间金字塔</p>

<hr />

<p><img src="../images/Image-Representation-For-Classification/ScSPM.png" alt="classification-framework" /></p>

<ul>
  <li><strong><em>ScSPM:</em></strong><br />
1.局部特征提取与描述；<br />
2.学习用于稀疏编码的视词字典；<br />
3.对局部特征进行稀疏编码；<br />
4.对稀疏编码后的特征利用Pooling方法计算空间金字塔。  </li>
</ul>

<hr />

<p><img src="../images/Image-Representation-For-Classification/LLC.png" alt="classification-framework" /></p>

<ul>
  <li><strong><em>LLC:</em></strong><br />
1.局部特征提取与描述；<br />
2.学习用于稀疏编码的视词字典；<br />
3.对局部特征进行局部约束线性编码；<br />
4.对稀疏编码后的特征利用Pooling方法计算空间金字塔。  </li>
</ul>

<hr />

<h2 id="section-2">图像表示模型性能评估</h2>

<p>实验数据集共有15类场景，每一类场景包括200+图像，数据集最初来源于<a href="http://www.di.ens.fr/willow/pdfs/cvpr06b.pdf">Lazebnik et al. 2006</a>。</p>

<p>在实验中，为了考察不同的参数对实验结果的影响，对于每种参数设置都进行了实验，每个实验随机选择训练集运行10次，最后取精度平均值。</p>

<hr />

<p>分类器选择线性支持向量机LinearSVM(λ为LinearSVM的则化参数)时的结果：</p>

<p><img src="../images/Image-Representation-For-Classification/LinearSVM-Tr.png" alt="classification-framework" /></p>

<p><img src="../images/Image-Representation-For-Classification/LinearSVM-Dic.png" alt="classification-framework" /></p>

<p><img src="../images/Image-Representation-For-Classification/LinearSVM-lambda.png" alt="classification-framework" /></p>

<hr />

<p>当用非线性SVM(LibSVM库)时，核函数的类型有线性核(Linear)、多项式核(Polynomial)、径向基函数核(RBF)和S型核(Sigmoid)，非线性SVM只对ScSPM方法进行了实验，结果如下：</p>

<p><img src="../images/Image-Representation-For-Classification/Kernel-ScSPM-Tr.png" alt="classification-framework" /></p>

<p><img src="../images/Image-Representation-For-Classification/Kernel-ScSPM-Dic.png" alt="classification-framework" /></p>

<hr />

<p>下面是ScSPM图像表示方法下，每类选100幅图像作为训练，在线性SVM分类时的混淆矩阵(右下角处类别的混淆较大，这主要是这些类的图像本来就比较相似)：</p>

<p><img src="../images/Image-Representation-For-Classification/Confusion-Matrix.png" alt="classification-framework" /></p>

<h2 id="section-3">结论</h2>

<p>在所考察的4中表示模型中，ScSPM的方法分类精度是最高的，但是其时间复杂度也比较大，如果对时间要求比较严格，分类精度适当降低可以接受，那么LLC方法是很好的选择。</p>

<h2 id="section-4">参考文献</h2>

<p>[1]	J. Sivic, A. Zisserman. Video Google: A Text Retrieval Approach to Object Matching in Videos. In ICCV, 2003.<br />
[2]	S. Lazebnik, C. Schmid, J. Ponce. Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories. In CVPR, 2006.<br />
[3]	J. Yang,  K. Yu,  Y. Gong, et al. Linear Spatial Pyramid Matching Using Sparse Coding for Image Classification[C]. In CVPR,2009.<br />
[4]	Jinjun Wang, Jianchao Yang,et al.Locality-constrained Linear Coding for Image Classification.in CVPR,2010.  </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Compress Sensing]]></title>
    <link href="http://yiiwood.github.com/blog/2012/10/23/sparse-lowrank/"/>
    <updated>2012-10-23T18:54:00+08:00</updated>
    <id>http://yiiwood.github.com/blog/2012/10/23/sparse-lowrank</id>
    <content type="html"><![CDATA[<h2 id="section">还没写，先放这</h2>

<p>我摘抄总结的
<a href="/images/Sparse Model for Data.pdf">Sparse Model for Data</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ensemble Learning]]></title>
    <link href="http://yiiwood.github.com/blog/2012/10/20/ensemble-learning/"/>
    <updated>2012-10-20T19:33:00+08:00</updated>
    <id>http://yiiwood.github.com/blog/2012/10/20/ensemble-learning</id>
    <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>思想起源于Valiant提出的PAC( Probably Approximately Correct)学习模型。Valiant和Kearns提出了弱学习和强学习的概念,识别错误率小于1/2,也即准确率仅比随机猜测略高的学习算法称为弱学习算法;识别准确率很高并能在多项式时间内完成的学习算法称为强学习算法。同时,Valiant和Kearns首次提出了PAC学习模型中弱学习算法和强学习算法的等价性问题,即任意给定仅比随机猜测略好的弱学习算法,是否可以将其提升为强学习算法?如果二者等价,那么只需找到一个比随机猜测略好的弱学习算法就可以将其提升为强学习算法,而不必寻找很难获得的强学习算法。</p>

<!-- more -->

<p>1990年,Schapire最先构造出一种多项式级的算法,对该问题做了肯定的证明,这就是最初的Boosting算法。一年后,Freund提出了一种效率更高的Boosting算法。但是,这两种算法存在共同的实践上的缺陷,那就是都要求事先知道弱学习算法学习正确的下限。1995年,Freund和schapire改进了Boosting算法,提出了AdaBoost (Adaptive Boosting)算法[5],该算法效率和Freund于1991年提出的Boosting算法几乎相同,但不需要任何关于弱学习器的先验知识,因而更容易应用到实际问题当中。之后, Freund和 schapire进一步提出了改变Boosting投票权重的AdaBoost .M1,AdaBoost .M2等算法 ,</p>

<p>Bagging是Breiman提出的与Boosting相似的技术。Bagging技术的主要思想是给定一弱学习算法和一训练集。让该学习算法训练多轮，每轮的训练集由从初始的训练集中随机取出的n个训练例组成，初始训练例在某轮训练集中可以出现多次或根本不出现。训练之后可得到一个预测函数序列，最终的预测函数是对分类问题采用投票方式，对回归问题采用简单平均方法对新示例进行判别。稳定性是Bagging能否提高预测准确率的关键因素：Bagging对不稳定的学习算法能提高预测的准确度，而对稳定的学习算法效果不明显，有时甚至使预测精确度降低。学习算法的不稳定性是指如果训练集有较小的变化，学习算法产生的预测函数将发生较大变化。判定树、神经网络是不稳定的，而最近邻方法是稳定的。</p>

<p>Bagging(Bootstrap Aggregating)与Boosting的区别在于Bagging的训练集的选择是随机的，各轮训练集之间相互独立，而Boosting的训练集的选择不是独立的，各轮训练集的选择与前面各轮的学习结果有关；Bagging的各个预测函数没有权重，而Boosting是有权重的；Bagging的各个预测函数可以并行生成，而Boosting的各个预测函数只能顺序生成。对于象神经网络这样极为耗时的学习方法，Bagging可通过并行训练节省大量时间开销。
Bagging对于噪声容忍程度比较好，而Boosting似乎对噪声容忍程度不高。</p>

]]></content>
  </entry>
  
</feed>
